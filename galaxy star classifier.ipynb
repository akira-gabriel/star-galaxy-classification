{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=\"data\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_noNorm = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = torch.zeros(1)\n",
    "total_sqsum = torch.zeros(1)\n",
    "total_pixels = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_noNorm:\n",
    "        b = images.shape[0]\n",
    "        c = images.shape[1]\n",
    "        h = images.shape[2]\n",
    "        w = images.shape[3]\n",
    "\n",
    "        sum_batch = torch.sum(images, dim=(0, 2, 3))\n",
    "        sqsum_batch = torch.sum(images**2, dim=(0, 2, 3))\n",
    "        pixels_batch = b * h * w\n",
    "\n",
    "        total_sum += sum_batch\n",
    "        total_sqsum += sqsum_batch\n",
    "        total_pixels += pixels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média:  0.3573446571826935\n",
      "Desvio padrão:  0.14582973718643188\n"
     ]
    }
   ],
   "source": [
    "mean = total_sum / total_pixels\n",
    "var = total_sqsum / total_pixels - mean**2\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print(\"Média: \", mean.item())\n",
    "print(\"Desvio padrão: \", std.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mean.item()\n",
    "s = std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[m], std=[s])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = v2.Compose([\n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.Resize((128, 128)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[m], std=[s])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['galaxy', 'star']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root='data', transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsize = len(train_dataset)\n",
    "train_size = int(0.7 * totalsize)\n",
    "val_size = int(0.15 * totalsize)\n",
    "test_size = totalsize - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = random_split(train_dataset,[train_size, val_size, test_size], torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_df, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_df, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_df, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3985, Train: 2789, Validation: 597, Test: 599\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total: {len(train_df + val_df + test_df)}, Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média batch:  0.0726\n",
      "Desvio padrão batch: 1.0696\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "it_loader = iter(train_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    images, labels = next(it_loader)\n",
    "    mean_batch = images.mean(dim=(0, 2, 3))\n",
    "    std_batch = images.std(dim=(0, 2, 3), unbiased=False)\n",
    "\n",
    "    print(f\"Média batch:  {mean_batch.item():.4f}\")\n",
    "    print(f\"Desvio padrão batch: {std_batch.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4504237174987793 4.406888484954834\n"
     ]
    }
   ],
   "source": [
    "print(images.min().item(), images.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.Grayscale(num_output_channels=1,\n",
    "                 v2.)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((8, 8))\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "model = CNN(num_classes=2)\n",
    "\n",
    "dummy = torch.randn(1, 1, 150, 150)\n",
    "out = model(dummy)\n",
    "\n",
    "print(\"Output:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion  = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração [1/10] Loss: 0.5948 Acurácia: 75.80%\n",
      "Geração [2/10] Loss: 0.5377 Acurácia: 76.30%\n",
      "Geração [3/10] Loss: 0.5291 Acurácia: 76.12%\n",
      "Geração [4/10] Loss: 0.5252 Acurácia: 76.30%\n",
      "Geração [5/10] Loss: 0.4894 Acurácia: 76.30%\n",
      "Geração [6/10] Loss: 0.4232 Acurácia: 80.06%\n",
      "Geração [7/10] Loss: 0.3681 Acurácia: 83.11%\n",
      "Geração [8/10] Loss: 0.3412 Acurácia: 85.48%\n",
      "Geração [9/10] Loss: 0.3309 Acurácia: 85.87%\n",
      "Geração [10/10] Loss: 0.3211 Acurácia: 86.55%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Geração [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Acurácia: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.adative_pool = nn.AdaptiveMaxPool2d((12, 12))\n",
    "        self.fc1 = nn.Linear(144 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.adative_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "model = CNN_2(num_classes=2)\n",
    "\n",
    "dummy = torch.randn(1, 1, 150, 150)\n",
    "out = model(dummy)\n",
    "\n",
    "print(\"Output:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração [1/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [2/10] Loss: 0.6834 Acurácia: 76.30%\n",
      "Geração [3/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [4/10] Loss: 0.6834 Acurácia: 76.30%\n",
      "Geração [5/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [6/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [7/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [8/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [9/10] Loss: 0.6833 Acurácia: 76.30%\n",
      "Geração [10/10] Loss: 0.6834 Acurácia: 76.30%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Geração [{epoch+1}/{num_epochs}] Loss: {epoch_loss:.4f} Acurácia: {epoch_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star-galaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
